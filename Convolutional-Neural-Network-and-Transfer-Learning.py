# -*- coding: utf-8 -*-
"""17011907_AyseHilalDogan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ztdQFnu5b3Bi2APIBuhlAaTX1HwOXlnO
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import datasets, layers, models,initializers
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import PIL.Image
import pandas as pd
import torch
from sklearn.metrics import confusion_matrix , classification_report
from keras_preprocessing.image import ImageDataGenerator

# Get the GPU device name.
device_name = tf.test.gpu_device_name()

# The device name should look like the following:
if device_name == '/device:GPU:0':
    print('Found GPU at: {}'.format(device_name))
else:
    raise SystemError('GPU device not found')

import torch

# If there's a GPU available...
if torch.cuda.is_available():    

    # Tell PyTorch to use the GPU.    
    device = torch.device("cuda")

    print('There are %d GPU(s) available.' % torch.cuda.device_count())
    print('We will use the GPU:', torch.cuda.get_device_name(0))

# If not...
else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")

! pip install -q kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download -d mengcius/cinic10

! unzip /content/cinic10.zip

batch_size = 64

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255)

train_generator = datagen.flow_from_directory(
    directory='/content/train',
    target_size=(224,224),
    class_mode='categorical',
    batch_size=batch_size, 
    )

val_generator = datagen.flow_from_directory(
    directory='/content/valid',
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    )

test_generator = datagen.flow_from_directory(
    directory='/content/test',
    target_size=(224,224),
    batch_size=batch_size,
    class_mode='categorical',
    )

model = models.Sequential()

model.add(layers.Conv2D(32, (3,3), activation='relu',kernel_initializer='GlorotNormal', input_shape=(224,224,3)))
model.add(layers.MaxPooling2D((1,1)))
model.add(layers.Dropout(0.7))
    
model.add(layers.Conv2D(32, (3,3), activation='relu',kernel_initializer='GlorotNormal'))
model.add(layers.MaxPooling2D((1,1)))
model.add(layers.Dropout(0.7))
    

model.add(layers.Flatten())
model.add(layers.Dense(batch_size, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

model.compile(optimizer='adam', 
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_generator, validation_data = val_generator, epochs=10)

model.summary()

model.save("33_07.h5")

loss,acc = model.evaluate(train_generator,verbose=2)
print("Train Loss:", loss)
print("Train Accuracy:", acc)

loss,acc = model.evaluate(test_generator,verbose=2)
print("Test Loss:", loss)
print("Test Accuracy:", acc)

prediction = model.predict(train_generator)
#prediction[:5]

print("Confusion Matrix:")
classes = [np.argmax(element) for element in prediction]
classes[:10]

"""2)"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.preprocessing import image_dataset_from_directory
import tensorflow_hub as hub

base_model = keras.applications.ResNet50(weights='imagenet',include_top=True)

#Do the model untrainable
base_model.trainable = False

base_model.summary()

#make last 3 layers untrainable

for layer in base_model.layers[:-3]:
  layer.trainable = False

base_model.summary()

#delete the last fully connected layer and then add a fully connected layer with 1024 neurons

base_inputs = base_model.layers[0].input
base_outputs = base_model.layers[-2].output
final_outputs = layers.Dense(1024,activation='relu')(base_outputs)
final_outputs = layers.Dense(10,activation='softmax')(final_outputs)

new_model = keras.Model(inputs=base_inputs, outputs = final_outputs)

new_model.compile(optimizer='adam', 
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

print(new_model.summary())

new_model.fit(train_generator, validation_data = val_generator, batch_size=64, epochs=10)

#train loss,accuracy

loss,acc = model.evaluate(train_generator,verbose=2)
print("Train Loss:", loss)
print("Train Accuracy:", acc)

#test loss,accuracy

loss,acc = model.evaluate(test_generator,verbose=2)
print("Test Loss:", loss)
print("Test Accuracy:", acc)

#Confusion Matrix 
prediction = new_model.predict(train_generator)

print("Confusion Matrix:")
classes = [np.argmax(element) for element in prediction]
classes[:10]

model.save("vgg16_2.h5")


"""#3)"""

from keras.preprocessing import image
#from keras.applications.vgg16 import preprocess_input,decode_predictions
from keras.applications.resnet50 import preprocess_input, decode_predictions

#Cosine Similarity Function

import math
from math import sqrt

def cosine(a,b):
    sum = 0
    suma = 0
    sumb = 0
    for i,j in (a, b):
        suma += i * i
        sumb += j*j
        sum += i*j
    cosine_sim = sum / (sqrt(suma)*sqrt(sumb))
    return cosine_sim

import random

#take random image
id = int(len(images) * random.random())

#display image
img = image.load_img(images[id])
plt.imshow(img)

feature_extractor = keras.Model( inputs=new_model.inputs, outputs=new_model.get_layer(name="dense_8").output )

#path = '/content/train/frog/cifar10-train-10007.png'

img = image.load_img(path , target_size=model.input_shape[1:3])

x = image.img_to_array(img)
plt.imshow(img)
